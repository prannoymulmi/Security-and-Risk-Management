{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010989,
     "end_time": "2021-02-19T22:09:18.619513",
     "exception": false,
     "start_time": "2021-02-19T22:09:18.608524",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Technique for Order of Preference by Similarity to Ideal Solution (AHP-TOPSIS)\n",
    "\n",
    "##### Modified from: https://www.kaggle.com/code/hungrybluedev/topsis-implementation/notebook </br>\n",
    "\n",
    "It is a multi-criteria decision analysis method that is based on the concept that the chosen alternative should have the shortest geometric distance to the Positive Ideal Solution (PIS) and the longest geometric solution from the Negative Ideal Solution (NIS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AHP Weight calculation\n",
    "1.  Pair-wise comparison of each criteria and sub-criteria to establish the weight of the supply chain parameters.\n",
    "2. Global summation of all these weights (weighted arithmetic sum) for each alternative and ordering them on the basis of this weighted sum.\n",
    "3. Calculate the consistency ratio which should be less than 0.10, otherwise the weights are not balanced"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AHP Pair-wise Comparison Matrix\n",
    "As the first step a pairwise comparison matrix is determined qualitatively according to the priority using the Saaty 9 point scale (Evelyn, E. et.al, 2015). This table is subjectively evaluated, as AHP combines both quantitative and qualitative aspects in the decision method, which helps the analysis to find the best possible answer rather than a correct solution (Longaray, A.A. et.al, 2015).\n",
    "<br /><br />\n",
    "\n",
    "| Features            | Digital Prepardness  | Natural Disaster | Labor Strikes | Political Stability | Logistic Index |\n",
    "|---------------------|----------------------|------------------|---------------|---------------------|----------------|\n",
    "| Digital Prepardness | 1                    | 6                | 8             | 4                   | 3              |\n",
    "| Natural Disaster    | 1/6                  | 1                | 3             | 1/2                 | 1/4            |\n",
    "| Labor Strikes       | 1/8                  | 1/3              | 1             | 1/2                 | 1/4            |\n",
    "| Political Stability | 1/4                  | 2                | 2             | 1                   | 1/3            |\n",
    "| Logistic Index      | 1/3                  | 4                | 4             | 3                   | 1              |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from ahpy import ahpy\n",
    "\n",
    "supply_chain_comp = {\n",
    "    ('Digital Prepardness', 'Digital Prepardness'): 1, ('Digital Prepardness', 'Natural Disasters'): 6, ('Digital Prepardness', 'Labor Strikes'): 8, ('Digital Prepardness', 'Political Stability'): 4, ('Digital Prepardness', 'Logistic Index'): 3,\n",
    "    ('Natural Disasters', 'Digital Prepardness'): 1/6, ('Natural Disasters', 'Natural Disasters'): 1, ('Natural Disasters', 'Labor Strikes'): 3, ('Natural Disasters', 'Political Stability'): 1/2, ('Natural Disasters', 'Logistic Index'): 1/5,\n",
    "    ('Labor Strikes', 'Digital Prepardness'): 1/8, ('Labor Strikes', 'Natural Disasters'): 1/3, ('Labor Strikes', 'Labor Strikes'): 1, ('Labor Strikes', 'Political Stability'): 1/2, ('Labor Strikes', 'Logistic Index'): 1/4,\n",
    "    ('Political Stability', 'Digital Prepardness'): 1/4, ('Political Stability', 'Natural Disasters'): 2, ('Political Stability', 'Labor Strikes'): 2, ('Political Stability', 'Political Stability'): 1, ('Political Stability', 'Logistic Index'): 1/3,\n",
    "    ('Logistic Index', 'Digital Prepardness'): 1/3, ('Logistic Index', 'Natural Disasters'): 4, ('Logistic Index', 'Labor Strikes'): 4, ('Logistic Index', 'Political Stability'): 3, ('Logistic Index', 'Logistic Index'): 1\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate the weight for the criteria\n",
    "The above table represents an n x n comparison matrix which contains the intensities defined by us (Karmaker, C.L et.al, 2018). $$\n",
    " M = (w_{i}/w_{j})_{n \\times n} = \\begin{pmatrix}{cc}\n",
    "w_{1}/w_{1} & w_{1}/w_{2} & .... & w_{1}/w_{n}\\\\\n",
    "w_{2}/w_{1} & w_{2}/w_{2} & .... & w_{2}/w_{n}\\\\\n",
    "\\vdots &\\vdots & \\vdots & \\vdots \\\\\n",
    "w_{n}/w_{1} & w_{n}/w_{2} & .... & w_{n}/w_{n}\n",
    "\\end{pmatrix}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate the weights\n",
    "The n x n matrix is first normalized using the formula below and a priority vector is generated with which the weights are generated.\n",
    "$$\n",
    "W = \\begin{bmatrix}\n",
    "           w_{1} \\\\\n",
    "           w_{2} \\\\\n",
    "           \\vdots \\\\\n",
    "           w_{n}\n",
    "         \\end{bmatrix}\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "supply_chain = ahpy.Compare(name='Supply_Chain', comparisons=supply_chain_comp, precision=3, random_index='saaty')\n",
    "\n",
    "print(supply_chain.target_weights)\n",
    "print('Consistency Ratio: ' + str(supply_chain.consistency_ratio))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate and check the Consistency ratio\n",
    "It is assumed that the experts using the AHP makers are objective. However, this is not true in real life which generates a certain level of uncertainty towards this evaluation. Therefore, Saaty solved this issue by creating the consistency Index and consistency ratios. To accept the matrix, the CR value should be less the 0.1 meaning there could be an inconsistency error of 10%."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:18.644908Z",
     "iopub.status.busy": "2021-02-19T22:09:18.644086Z",
     "iopub.status.idle": "2021-02-19T22:09:19.425988Z",
     "shell.execute_reply": "2021-02-19T22:09:19.426526Z"
    },
    "papermill": {
     "duration": 0.797664,
     "end_time": "2021-02-19T22:09:19.426895",
     "exception": false,
     "start_time": "2021-02-19T22:09:18.629231",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# All the packages that we need to import\n",
    "import numpy as np               # for linear algebra\n",
    "import pandas as pd              # for tabular output\n",
    "from scipy.stats import rankdata # for ranking the candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009821,
     "end_time": "2021-02-19T22:09:19.448201",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.438380",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-requisites\n",
    "\n",
    "For this problem, we are always provided with the following data:\n",
    "1. The ratings in every category for each candidate.\n",
    "2. The weights for every category or attribute to be considered.\n",
    "\n",
    "Note that an attribute can be beneficial attribute (in which case, we will want to maximize it's contribution) or a cost attribute (which we will need to minimize). We call the set of beneficial attributes $J_1$ and that of cost attributes $J_2 = J_1^C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# The given data encoded into vectors and matrices\n",
    "\n",
    "attributes = np.array([\"Digital Prepardness\", \"Natural Disasters\", \"Labor Strikes\", \"Political Stability\", \"Logistic Index\"])\n",
    "candidates = np.array([\"Germany\", \"Poland\", \"France\", \"Belgium\",\"UK\", \"Portugal\", \"Bulgaria\", \"Netherlands\", \"Spain\", \"Ireland\", \"Hungary\"])\n",
    "raw_data = np.array([\n",
    "    [88.07, 3.26, 17.30, 0.76, 4.10], # Germany\n",
    "    [84.09, 3.65, 16.0, 0.51, 3.6], # Poland\n",
    "    [86.41, 3.53, 127.6, 0.37, 3.9], # France\n",
    "    [90.69, 3.52, 97.9, 0.61, 4.0], # Belgium\n",
    "    [85.59, 4.058, 17.9, 0.54, 3.8], # UK\n",
    "    [85.5, 3.9, 14.1, 0., 3.4], # Portugal\n",
    "    [64.37, 3.88, 2.1, 0.46, 3.2], # Bulgaria\n",
    "    [84.66, 7.44, 19.2, 0.92, 4.1], # Netherlands\n",
    "    [88.61, 2.94, 49.1, 0.58, 3.9], # Spain\n",
    "    [78.56, 4.2, 15.6, 0.86, 3.6], # Ireland\n",
    "    [76.74, 4.68, 6.2, 0.86, 3.2], # Hungary\n",
    "])\n",
    "\n",
    "weights = np.array([0.503, 0.084, 0.05, 0.114, 0.249])\n",
    "\n",
    "# The indices of the attributes (zero-based) that are considered beneficial.\n",
    "# Those indices not mentioned are assumed to be cost attributes.\n",
    "# Cost benefit functions = when cost (lower is better) and 1 when benefit function (more is better)\n",
    "# This attribute sets if the colum is better with lower or higher data.\n",
    "benefit_attributes = set([0, 3, 4])\n",
    "\n",
    "# Display the raw data we have\n",
    "pd.DataFrame(data=raw_data, index=candidates, columns=attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010017,
     "end_time": "2021-02-19T22:09:19.534211",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.524194",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1 - Normalizing the ratings using Vector normalization\n",
    "\n",
    "$$r_{ij}=\\frac{x_{ij}}{\\sqrt{\\sum_{i = 1}^{m} x_{ij}^2}}$$\n",
    "\n",
    "where $i = 1, 2, \\ldots, m$ and $j = 1, 2, \\ldots, n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:19.558504Z",
     "iopub.status.busy": "2021-02-19T22:09:19.557538Z",
     "iopub.status.idle": "2021-02-19T22:09:19.573872Z",
     "shell.execute_reply": "2021-02-19T22:09:19.574418Z"
    },
    "papermill": {
     "duration": 0.03022,
     "end_time": "2021-02-19T22:09:19.574605",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.544385",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m = len(raw_data)\n",
    "n = len(attributes)\n",
    "divisors = np.empty(n)\n",
    "for j in range(n):\n",
    "    column = raw_data[:,j]\n",
    "    divisors[j] = np.sqrt(column @ column)\n",
    "\n",
    "raw_data /= divisors\n",
    "\n",
    "columns = [\"$X_{%d}$\" % j for j in range(n)]\n",
    "pd.DataFrame(data=raw_data, index=candidates, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010523,
     "end_time": "2021-02-19T22:09:19.596095",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.585572",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2 - Calculating the Weighted Normalized Ratings\n",
    "\n",
    "$$v_{ij} = w_j r_{ij}$$\n",
    "\n",
    "where $i = 1, 2, \\ldots, m$ and $j = 1, 2, \\ldots, n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:19.631855Z",
     "iopub.status.busy": "2021-02-19T22:09:19.631167Z",
     "iopub.status.idle": "2021-02-19T22:09:19.634040Z",
     "shell.execute_reply": "2021-02-19T22:09:19.634496Z"
    },
    "papermill": {
     "duration": 0.027928,
     "end_time": "2021-02-19T22:09:19.634687",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.606759",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              $X_{0}$   $X_{1}$   $X_{2}$   $X_{3}$   $X_{4}$\nGermany      0.160292  0.019408  0.004994  0.040789  0.082686\nPoland       0.153048  0.021730  0.004618  0.027371  0.072603\nFrance       0.157271  0.021016  0.036831  0.019858  0.078653\nBelgium      0.165061  0.020956  0.028258  0.032738  0.080670\nUK           0.155778  0.024159  0.005167  0.028981  0.076636\nPortugal     0.155615  0.023219  0.004070  0.000000  0.068569\nBulgaria     0.117157  0.023100  0.000606  0.024688  0.064536\nNetherlands  0.154086  0.044294  0.005542  0.049376  0.082686\nSpain        0.161275  0.017503  0.014172  0.031128  0.078653\nIreland      0.142983  0.025005  0.004503  0.046156  0.072603\nHungary      0.139671  0.027862  0.001790  0.046156  0.064536",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>$X_{0}$</th>\n      <th>$X_{1}$</th>\n      <th>$X_{2}$</th>\n      <th>$X_{3}$</th>\n      <th>$X_{4}$</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Germany</th>\n      <td>0.160292</td>\n      <td>0.019408</td>\n      <td>0.004994</td>\n      <td>0.040789</td>\n      <td>0.082686</td>\n    </tr>\n    <tr>\n      <th>Poland</th>\n      <td>0.153048</td>\n      <td>0.021730</td>\n      <td>0.004618</td>\n      <td>0.027371</td>\n      <td>0.072603</td>\n    </tr>\n    <tr>\n      <th>France</th>\n      <td>0.157271</td>\n      <td>0.021016</td>\n      <td>0.036831</td>\n      <td>0.019858</td>\n      <td>0.078653</td>\n    </tr>\n    <tr>\n      <th>Belgium</th>\n      <td>0.165061</td>\n      <td>0.020956</td>\n      <td>0.028258</td>\n      <td>0.032738</td>\n      <td>0.080670</td>\n    </tr>\n    <tr>\n      <th>UK</th>\n      <td>0.155778</td>\n      <td>0.024159</td>\n      <td>0.005167</td>\n      <td>0.028981</td>\n      <td>0.076636</td>\n    </tr>\n    <tr>\n      <th>Portugal</th>\n      <td>0.155615</td>\n      <td>0.023219</td>\n      <td>0.004070</td>\n      <td>0.000000</td>\n      <td>0.068569</td>\n    </tr>\n    <tr>\n      <th>Bulgaria</th>\n      <td>0.117157</td>\n      <td>0.023100</td>\n      <td>0.000606</td>\n      <td>0.024688</td>\n      <td>0.064536</td>\n    </tr>\n    <tr>\n      <th>Netherlands</th>\n      <td>0.154086</td>\n      <td>0.044294</td>\n      <td>0.005542</td>\n      <td>0.049376</td>\n      <td>0.082686</td>\n    </tr>\n    <tr>\n      <th>Spain</th>\n      <td>0.161275</td>\n      <td>0.017503</td>\n      <td>0.014172</td>\n      <td>0.031128</td>\n      <td>0.078653</td>\n    </tr>\n    <tr>\n      <th>Ireland</th>\n      <td>0.142983</td>\n      <td>0.025005</td>\n      <td>0.004503</td>\n      <td>0.046156</td>\n      <td>0.072603</td>\n    </tr>\n    <tr>\n      <th>Hungary</th>\n      <td>0.139671</td>\n      <td>0.027862</td>\n      <td>0.001790</td>\n      <td>0.046156</td>\n      <td>0.064536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data *= weights\n",
    "pd.DataFrame(data=raw_data, index=candidates, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011047,
     "end_time": "2021-02-19T22:09:19.657165",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.646118",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3 - Identifying PIS ($A^*$) and NIS ($A^-$)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A^* &= \\left\\{v_1^*, v_2^*, \\ldots, v_n^*\\right\\} \\\\\n",
    "A^- &= \\left\\{v_1^-, v_2^-, \\ldots, v_n^-\\right\\} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And we define\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "v_j^* &=\n",
    "\\begin{cases}\n",
    "\\max{(v_{ij})}, \\text{ if} j \\in J_1 \\\\\n",
    "\\min{(v_{ij})}, \\text{ if} j \\in J_2\n",
    "\\end{cases}\n",
    "\\\\\n",
    "v_j^- &=\n",
    "\\begin{cases}\n",
    "\\min{(v_{ij})}, \\text{ if} j \\in J_1 \\\\\n",
    "\\max{(v_{ij})}, \\text{ if} j \\in J_2\n",
    "\\end{cases}\n",
    "\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $i = 1, 2, \\ldots, m$ and $j = 1, 2, \\ldots, n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:19.683607Z",
     "iopub.status.busy": "2021-02-19T22:09:19.682916Z",
     "iopub.status.idle": "2021-02-19T22:09:19.698532Z",
     "shell.execute_reply": "2021-02-19T22:09:19.698992Z"
    },
    "papermill": {
     "duration": 0.030628,
     "end_time": "2021-02-19T22:09:19.699195",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.668567",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        $X_{0}$   $X_{1}$   $X_{2}$   $X_{3}$   $X_{4}$\n$A^*$  0.165061  0.017503  0.000606  0.049376  0.082686\n$A^-$  0.117157  0.044294  0.036831  0.000000  0.064536",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>$X_{0}$</th>\n      <th>$X_{1}$</th>\n      <th>$X_{2}$</th>\n      <th>$X_{3}$</th>\n      <th>$X_{4}$</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>$A^*$</th>\n      <td>0.165061</td>\n      <td>0.017503</td>\n      <td>0.000606</td>\n      <td>0.049376</td>\n      <td>0.082686</td>\n    </tr>\n    <tr>\n      <th>$A^-$</th>\n      <td>0.117157</td>\n      <td>0.044294</td>\n      <td>0.036831</td>\n      <td>0.000000</td>\n      <td>0.064536</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_pos = np.zeros(n)\n",
    "a_neg = np.zeros(n)\n",
    "for j in range(n):\n",
    "    column = raw_data[:,j]\n",
    "    max_val = np.max(column)\n",
    "    min_val = np.min(column)\n",
    "    \n",
    "    # See if we want to maximize benefit or minimize cost (for PIS)\n",
    "    if j in benefit_attributes:\n",
    "        a_pos[j] = max_val\n",
    "        a_neg[j] = min_val\n",
    "    else:\n",
    "        a_pos[j] = min_val\n",
    "        a_neg[j] = max_val\n",
    "\n",
    "pd.DataFrame(data=[a_pos, a_neg], index=[\"$A^*$\", \"$A^-$\"], columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011753,
     "end_time": "2021-02-19T22:09:19.723072",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.711319",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 4 and 5 - Calculating Separation Measures and Similarities to PIS\n",
    "\n",
    "The separation or distance between the alternatives can be measured by the $n$-dimensional Euclidean distance. The separation from the PIS $A^*$ and NIS $A^-$ are $S^*$ and $S^-$ respectively.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "S_i^* &= \\sqrt{\\sum_{j = 1}^n \\left(v_{ij} - v^*_j\\right)^2} \\\\\n",
    "S_i^- &= \\sqrt{\\sum_{j = 1}^n \\left(v_{ij} - v^-_j\\right)^2} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $i = 1, 2, \\ldots, m$ and $j = 1, 2, \\ldots, n$.\n",
    "\n",
    "We also calculate\n",
    "\n",
    "$$\n",
    "C^*_i = \\frac{S_i^-}{S_i^* + S_i^-},\\text{ where }i = 1, 2, \\ldots, m\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:19.750405Z",
     "iopub.status.busy": "2021-02-19T22:09:19.749766Z",
     "iopub.status.idle": "2021-02-19T22:09:19.764407Z",
     "shell.execute_reply": "2021-02-19T22:09:19.764896Z"
    },
    "papermill": {
     "duration": 0.029903,
     "end_time": "2021-02-19T22:09:19.765068",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.735165",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                $S^*$     $S^-$     $C^*$\nGermany      0.010925  0.074072  0.871467\nPoland       0.027643  0.060409  0.686061\nFrance       0.047674  0.052389  0.523559\nBelgium      0.032518  0.065154  0.667067\nUK           0.024572  0.062338  0.717268\nPortugal     0.052642  0.054888  0.510447\nBulgaria     0.057140  0.048692  0.460087\nNetherlands  0.029369  0.071485  0.708795\nSpain        0.023401  0.065923  0.738019\nIreland      0.025902  0.065419  0.716363\nHungary      0.033063  0.064305  0.660432",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>$S^*$</th>\n      <th>$S^-$</th>\n      <th>$C^*$</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Germany</th>\n      <td>0.010925</td>\n      <td>0.074072</td>\n      <td>0.871467</td>\n    </tr>\n    <tr>\n      <th>Poland</th>\n      <td>0.027643</td>\n      <td>0.060409</td>\n      <td>0.686061</td>\n    </tr>\n    <tr>\n      <th>France</th>\n      <td>0.047674</td>\n      <td>0.052389</td>\n      <td>0.523559</td>\n    </tr>\n    <tr>\n      <th>Belgium</th>\n      <td>0.032518</td>\n      <td>0.065154</td>\n      <td>0.667067</td>\n    </tr>\n    <tr>\n      <th>UK</th>\n      <td>0.024572</td>\n      <td>0.062338</td>\n      <td>0.717268</td>\n    </tr>\n    <tr>\n      <th>Portugal</th>\n      <td>0.052642</td>\n      <td>0.054888</td>\n      <td>0.510447</td>\n    </tr>\n    <tr>\n      <th>Bulgaria</th>\n      <td>0.057140</td>\n      <td>0.048692</td>\n      <td>0.460087</td>\n    </tr>\n    <tr>\n      <th>Netherlands</th>\n      <td>0.029369</td>\n      <td>0.071485</td>\n      <td>0.708795</td>\n    </tr>\n    <tr>\n      <th>Spain</th>\n      <td>0.023401</td>\n      <td>0.065923</td>\n      <td>0.738019</td>\n    </tr>\n    <tr>\n      <th>Ireland</th>\n      <td>0.025902</td>\n      <td>0.065419</td>\n      <td>0.716363</td>\n    </tr>\n    <tr>\n      <th>Hungary</th>\n      <td>0.033063</td>\n      <td>0.064305</td>\n      <td>0.660432</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = np.zeros(m)\n",
    "sn = np.zeros(m)\n",
    "cs = np.zeros(m)\n",
    "\n",
    "for i in range(m):\n",
    "    diff_pos = raw_data[i] - a_pos\n",
    "    diff_neg = raw_data[i] - a_neg\n",
    "    sp[i] = np.sqrt(diff_pos @ diff_pos)\n",
    "    sn[i] = np.sqrt(diff_neg @ diff_neg)\n",
    "    cs[i] = sn[i] / (sp[i] + sn[i])\n",
    "\n",
    "pd.DataFrame(data=zip(sp, sn, cs), index=candidates, columns=[\"$S^*$\", \"$S^-$\", \"$C^*$\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012163,
     "end_time": "2021-02-19T22:09:19.790932",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.778769",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 6 - Ranking the candidates/alternatives\n",
    "\n",
    "We choose the candidate with the maximum $C^*$ or rank all the alternatives in descending order according to their $C^*$ values. This process can also be done for the $S^*$ and $S^-$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:19.820620Z",
     "iopub.status.busy": "2021-02-19T22:09:19.819968Z",
     "iopub.status.idle": "2021-02-19T22:09:19.825821Z",
     "shell.execute_reply": "2021-02-19T22:09:19.825149Z"
    },
    "papermill": {
     "duration": 0.022261,
     "end_time": "2021-02-19T22:09:19.825967",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.803706",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rank_according_to(data):\n",
    "    ranks = rankdata(data).astype(int)\n",
    "    ranks -= 1\n",
    "    return candidates[ranks][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:19.860862Z",
     "iopub.status.busy": "2021-02-19T22:09:19.860168Z",
     "iopub.status.idle": "2021-02-19T22:09:19.872164Z",
     "shell.execute_reply": "2021-02-19T22:09:19.872620Z"
    },
    "papermill": {
     "duration": 0.032593,
     "end_time": "2021-02-19T22:09:19.872798",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.840205",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cs_order = rank_according_to(cs)\n",
    "sp_order = rank_according_to(sp)\n",
    "sn_order = rank_according_to(sn)\n",
    "\n",
    "pd.DataFrame(data=zip(cs_order, sp_order, sn_order), index=range(1, m + 1), columns=[\"$C^*$\", \"$S^*$\", \"$S^-$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-19T22:09:19.905499Z",
     "iopub.status.busy": "2021-02-19T22:09:19.904809Z",
     "iopub.status.idle": "2021-02-19T22:09:19.909439Z",
     "shell.execute_reply": "2021-02-19T22:09:19.908894Z"
    },
    "papermill": {
     "duration": 0.023422,
     "end_time": "2021-02-19T22:09:19.909587",
     "exception": false,
     "start_time": "2021-02-19T22:09:19.886165",
     "status": "completed"
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best candidate/alternative according to C* is Belgium\n",
      "The preferences in descending order are Belgium, Netherlands, Ireland, Bulgaria, Germany, Poland, Spain, UK, France, Portugal, Hungary.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best candidate/alternative according to C* is \" + cs_order[0])\n",
    "print(\"The preferences in descending order are \" + \", \".join(cs_order) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "Evelyn, E. and EdmondYeboah, N., (2015). Ranking Agricultural Supply Chain Risk in Ghana: An AHP Approach. International Journal of Economics,Commerece and Management, III, 2, pp.1-12.\n",
    "\n",
    "Hungrybluedev (2021) Topsis implementation, Kaggle. Available from: https://www.kaggle.com/code/hungrybluedev/topsis-implementation/notebook (Accessed: 12 May 2023).\n",
    "\n",
    "Karmaker, C.L., Ahmed, S.M.T., Rahman, M.S., Tahiduzzaman, M., Biswas, T.K., Rahman, M. and Biswas, S.K., 2018. A framework of faculty performance evaluation: A case study in Bangladesh. International Journal of Research in Advanced Engineering and Technology, 4(3), pp.18-24.\n",
    "\n",
    "Longaray, A.A., Gois, J.D.D.R. and da Silva Munhoz, P.R., ()2015. Proposal for using AHP method to evaluate the quality of services provided by outsourced companies. Procedia Computer Science, 55, pp.715-724."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.183306,
   "end_time": "2021-02-19T22:09:20.734651",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-19T22:09:12.551345",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}